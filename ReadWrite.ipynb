{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKwnFgvbs/FzWv6/YGEHvZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eshita781996/ReadWrite/blob/main/ReadWrite.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t4aTUSkxT_j3"
      },
      "outputs": [],
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
        "!pip -q install findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
        "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages io.delta:delta-core_2.12:0.7.0 --conf spark.sql.extensions=io.delta.sql.DeltaSparkSessionExtension --conf spark.sql.catalog.spark_catalog=org.apache.spark.sql.delta.catalog.DeltaCatalog pyspark-shell'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "LpVIHjdvYLPo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "from pyspark.sql.types import *\n",
        "spark = SparkSession.builder.appName('delta_session').getOrCreate()"
      ],
      "metadata": {
        "id": "CB3q4bMKYOHf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Read from CSV\n",
        "df =  spark.read.option(\"header\", \"true\").csv('/content/sample_data/california_housing_test.csv')\n",
        "df.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbsPkM5sYT4n",
        "outputId": "5016e49e-51ec-448b-e183-8b20a730b58d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|  longitude| latitude|housing_median_age|total_rooms|total_bedrooms| population|households|median_income|median_house_value|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "|-122.050000|37.370000|         27.000000|3885.000000|    661.000000|1537.000000|606.000000|     6.608500|     344700.000000|\n",
            "|-118.300000|34.260000|         43.000000|1510.000000|    310.000000| 809.000000|277.000000|     3.599000|     176500.000000|\n",
            "+-----------+---------+------------------+-----------+--------------+-----------+----------+-------------+------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Read from JSON\n",
        "df =  spark.read.option(\"header\", \"true\").format('json').option(\"multiline\",\"true\") .load('/content/sample_data/anscombe.json')\n",
        "df.show(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbGL94DFY1uW",
        "outputId": "d475756e-b65f-4f6e-8243-6165e083f2c7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+----+----+\n",
            "|Series|   X|   Y|\n",
            "+------+----+----+\n",
            "|     I|10.0|8.04|\n",
            "|     I| 8.0|6.95|\n",
            "+------+----+----+\n",
            "only showing top 2 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "schema = {'emp_id':'string','emp_name':'integer','emp_city':'string','emp_salary':'integer'}\n",
        "print(schema)\n",
        "\n",
        "schema_of_csv = list()\n",
        "for i in schema:\n",
        "  schema_of_csv.append({'name': i,\\\n",
        "                       'type': schema[i],\\\n",
        "                       'nullable': False,\\\n",
        "                       'metadata':{}})\n",
        "\n",
        "print(schema_of_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXwMZsescKIb",
        "outputId": "507518c8-c916-4c9f-defc-57ac47e16936"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'emp_id': 'string', 'emp_name': 'integer', 'emp_city': 'string', 'emp_salary': 'integer'}\n",
            "[{'name': 'emp_id', 'type': 'string', 'nullable': False, 'metadata': {}}, {'name': 'emp_name', 'type': 'integer', 'nullable': False, 'metadata': {}}, {'name': 'emp_city', 'type': 'string', 'nullable': False, 'metadata': {}}, {'name': 'emp_salary', 'type': 'integer', 'nullable': False, 'metadata': {}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType.fromJson({'type':'struct','fields':schema_of_csv})\n",
        "print(schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uu8OQo1f_Ghr",
        "outputId": "80379d81-fd87-4510-9faf-d8b21bb9f5ba"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StructType(List(StructField(emp_id,StringType,false),StructField(emp_name,IntegerType,false),StructField(emp_city,StringType,false),StructField(emp_salary,IntegerType,false)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.schema(schema).option(\"mode\", \"DROPMALFORMED\").option('header','true').csv('/content/sample_data/sample.csv')\n",
        "df.show()\n",
        "df1 = spark.read.schema(schema).option(\"mode\", \"PERMISSIVE\").option('header','true').csv('/content/sample_data/sample.csv')\n",
        "df1.show()\n",
        "#df2 = spark.read.schema(schema).option(\"mode\", \"FAILFAST\").option('header','true').csv('/content/sample_data/sample.csv')\n",
        "#df2.show()\n",
        "print(df.dtypes)\n",
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT3ZKm48AMbb",
        "outputId": "dd88e4a4-90e3-4fb4-b988-45550d87ec07"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+--------+----------+\n",
            "|emp_id|emp_name|emp_city|emp_salary|\n",
            "+------+--------+--------+----------+\n",
            "+------+--------+--------+----------+\n",
            "\n",
            "+------+--------+---------+----------+\n",
            "|emp_id|emp_name| emp_city|emp_salary|\n",
            "+------+--------+---------+----------+\n",
            "|     1|    null|   Sydney|     35000|\n",
            "|     2|    null|Melbourne|     45000|\n",
            "|     3|    null|   Sydney|     55000|\n",
            "+------+--------+---------+----------+\n",
            "\n",
            "[('emp_id', 'string'), ('emp_name', 'int'), ('emp_city', 'string'), ('emp_salary', 'int')]\n",
            "['emp_id', 'emp_name', 'emp_city', 'emp_salary']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "employees_delta_df = spark.createDataFrame([(2, 'Peter', 'Melbourne', 55000.00),(5, 'Jessie', 'Brisbane', 42000.00)],\n",
        "                                           schema='emp_id int,emp_name string,emp_city string,emp_salary float')\n",
        "print(employees_delta_df.dtypes)\n",
        "print(employees_delta_df.columns)"
      ],
      "metadata": {
        "id": "JtIUVaa1bEuu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fda61cc0-9b9a-4850-a039-abced0480035"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('emp_id', 'int'), ('emp_name', 'string'), ('emp_city', 'string'), ('emp_salary', 'float')]\n",
            "['emp_id', 'emp_name', 'emp_city', 'emp_salary']\n"
          ]
        }
      ]
    }
  ]
}